# Initial Commit

This lab explores instrumenting a langchain and openai application with Opentelemtry traces and sending those traces to Dynatrace



## Lab overview

### LangChain

[Langchain](https://www.langchain.com/langchain) is framework that simplifies and abstracts working with Large Lange Models (LLMs) from various providers. 

For this lab we use LangChain's OpenAI integration to interact with the GPT4 model.

### OpenAI

For this lab we use OpenAI's gpt-4o model

You'll need to create an [OpenAI API key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key) which will be used to autheniticate requests from Langchain

###  Traceloop
Traceloop integrates with OpenLLMetry SDK and simplifies getting performance, code level traces from LLM applications to observability platforms.

### Streamlit

We use [streamlit](https://streamlit.io/) to simplify the creation of our front end LLM web app.  No Java, CSS exprience needed. 

### Dynatrace

We use the article [Traceloop OpenLLMetry](https://docs.dynatrace.com/docs/shortlink/dynatrace-traceloop-openllmetry) to send OTEL traces to Dynatrace


### Lab Components
![Lab Components](https://github.com/j-sulliman/langchain-web-app/blob/main/architecture_diagram.png?raw=true")



## Running the lab

### Open with Codespaces
asdsadas

###  Create virtual environment and install dependencies
sadasdasd


###  Set environment variables

sdasdd
